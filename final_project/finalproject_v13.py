# -*- coding: utf-8 -*-
"""FinalProject_v13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aqIbunxMYUTW2_YDspNGzc2ppGqfB_xe
"""

# ============================================================
# üß≠ University of San Diego - NLP & GenAI (AAI-520-IN3)
# Final Project: Multi-Agent Investment Research Report
# Authors: Richa Arun Kumar Jha, Raminder Singh, Samiksha Kodgire
# Instructor: Premkumar Chithaluru, Ph.D
# Date: 17 October 2025
# ============================================================

import warnings, numpy as np, pandas as pd, yfinance as yf, requests, torch, matplotlib.pyplot as plt, nltk
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
from nltk.corpus import stopwords
from IPython.display import Markdown, display, HTML

warnings.filterwarnings("ignore")
pd.set_option("display.max_colwidth", 80)
pd.set_option("display.width", 80)
plt.rcParams["figure.figsize"] = (7, 5)
plt.rcParams["savefig.bbox"] = "tight"

nltk.download("punkt")
nltk.download("stopwords")

# ============================================================
# üéì Title & Abstract
# ============================================================
display(Markdown("""
# üß≠ University of San Diego
## Natural Language Processing and GenAI (AAI-520-IN3)
### Final Project: Multi-Agent Investment Research Report

**Authors:** Richa Arun Kumar Jha, Raminder Singh, Samiksha Kodgire
**Instructor:** Premkumar Chithaluru, Ph.D
**Date:** 16 October 2025

---

### **Abstract**
This project presents a comprehensive AI-driven investment research system that integrates quantitative analysis, sentiment evaluation, and generative summarization through a **multi-agent architecture**.
Agents autonomously collect market data, perform risk and technical analyses, classify news sentiment using **DistilBERT**, and summarize insights using **Phi-3 Mini**.
The workflow covers six major technology tickers ‚Äî AAPL, GOOG, TSLA, AMZN, NVDA, and MSFT ‚Äî producing financial summaries, correlation analysis, and portfolio suggestions.
---
"""))

# ============================================================
# ‚öôÔ∏è Agentic Workflow Overview
# ============================================================
display(Markdown("""
## ‚öôÔ∏è Agentic Workflow Overview
1. **DataAgent** ‚Äî Fetches market data from Yahoo Finance.
2. **TechnicalAgent** ‚Äî Computes SMA20, SMA50, RSI, and momentum signal.
3. **RiskAgent** ‚Äî Evaluates volatility, drawdown, and composite risk score.
4. **NewsAgent** ‚Äî Retrieves live financial headlines from NewsAPI.
5. **SentimentAgent** ‚Äî Classifies news into Positive / Neutral / Negative using DistilBERT.
6. **RoutingAgent** ‚Äî Routes news to earnings, macro, or product categories.
7. **PortfolioAgent** ‚Äî Suggests risk-aligned asset allocation.
8. **EvaluationAgent** ‚Äî Compares sentiment trends vs. price action.
9. **LLMOptimizerAgent** ‚Äî Generates professional summaries using Phi-3 Mini.
---
"""))

# ============================================================
# üîß Setup
# ============================================================
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"‚úÖ Device: {device}")

# load keys from Colab secrets
from google.colab import userdata
NEWS_API_KEY = userdata.get("NEWS_API_KEY")

# models
sentiment_model = pipeline("sentiment-analysis",
                           model="distilbert-base-uncased-finetuned-sst-2-english",
                           device=0 if device=="cuda" else -1)
model_name = "microsoft/Phi-3-mini-4k-instruct"
model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map="auto")
tokenizer = AutoTokenizer.from_pretrained(model_name)
llm = pipeline("text-generation", model=model, tokenizer=tokenizer)

# ============================================================
# üìã Helper
# ============================================================
def md_table(df, title=None):
    """Render compact Markdown tables that print correctly on PDF."""
    txt = ""
    if title: txt += f"\n### {title}\n\n"
    txt += df.to_markdown(index=False, tablefmt="github")
    display(Markdown(txt))

# ============================================================
# ü§ñ Agents
# ============================================================
def fetch_data(ticker, period="1y"):
    return yf.download(ticker, period=period, progress=False).reset_index()

def compute_technicals(data):
    """Compute SMA20, SMA50, RSI, and signal ‚Äî guaranteed scalar-safe."""
    if data is None or data.empty or len(data) < 50:
        return {"SMA20": np.nan, "SMA50": np.nan, "RSI": 50.0, "Signal": "Neutral"}

    close = data["Close"].fillna(method="ffill").fillna(method="bfill")

    sma20 = close.rolling(20).mean().iloc[-1]
    sma50 = close.rolling(50).mean().iloc[-1]

    delta = close.diff()
    gain = delta.where(delta > 0, 0).rolling(14).mean()
    loss = -delta.where(delta < 0, 0).rolling(14).mean()
    rs = gain / loss

    last_loss = float(loss.iloc[-1:].values[0]) if not np.isnan(loss.iloc[-1:].values[0]) else 0.0
    last_rs = float(rs.iloc[-1:].values[0]) if not np.isnan(rs.iloc[-1:].values[0]) else 0.0

    if last_loss == 0 or np.isnan(last_rs):
        rsi = 50.0
    else:
        rsi = 100 - (100 / (1 + last_rs))

    signal = "Bullish" if float(sma20) > float(sma50) else "Bearish"

    return {
        "SMA20": float(sma20),
        "SMA50": float(sma50),
        "RSI": float(rsi),
        "Signal": signal,
    }

def compute_risk(data):
    """Compute volatility, drawdown, and risk score ‚Äî robust to NaN or short series."""
    if data is None or data.empty or len(data) < 2:
        return {"Volatility": np.nan, "Drawdown": np.nan, "RiskScore": np.nan}

    close = data["Close"].fillna(method="ffill").fillna(method="bfill")
    ret = close.pct_change().dropna()

    vol = float(ret.std()) if not ret.empty else 0.0
    dd_series = (close / close.cummax() - 1)
    dd = float(dd_series.min()) if not dd_series.empty else 0.0

    score = abs(vol * 1000 + dd * 100)
    return {
        "Volatility": vol,
        "Drawdown": dd,
        "RiskScore": round(score, 2),
    }

def fetch_news(ticker):
    url = f"https://newsapi.org/v2/everything?q={ticker}&apiKey={NEWS_API_KEY}&language=en&sortBy=publishedAt&pageSize=5"
    try:
        r = requests.get(url, timeout=10)
        return [a["title"] for a in r.json().get("articles", [])] or ["No news available."]
    except Exception as e:
        return [f"Error fetching news: {e}"]

def classify_sentiment(headlines):
    results = sentiment_model(headlines)
    counts = {"positive":0,"neutral":0,"negative":0}
    for r in results:
        if r["label"] == "POSITIVE": counts["positive"]+=1
        else: counts["negative"]+=1
    total = sum(counts.values()) or 1
    for k in counts: counts[k] = round(100*counts[k]/total, 1)
    return counts

def route_news(headlines):
    routes = {"earnings":[],"macro":[],"product":[]}
    for h in headlines:
        hl = h.lower()
        if any(k in hl for k in ["earnings","profit","revenue"]): routes["earnings"].append(h)
        elif any(k in hl for k in ["inflation","market","economy","rates"]): routes["macro"].append(h)
        else: routes["product"].append(h)
    return routes

def suggest_portfolio(risk):
    if risk < 30: return {"Equity":0.7,"Bonds":0.2,"Cash":0.1}
    elif risk < 50: return {"Equity":0.6,"Bonds":0.3,"Cash":0.1}
    else: return {"Equity":0.4,"Bonds":0.4,"Cash":0.2}

def compare_sentiment_vs_price(sent, data):
    try:
        if data is None or data.empty:
            return "Unknown"
        close = data["Close"].dropna().reset_index(drop=True)
        if len(close) < 2:
            return "Unknown"
        first_price = float(close.iloc[0])
        last_price = float(close.iloc[-1])
        up = last_price > first_price
        pos = float(sent.get("positive", 0))
        neg = float(sent.get("negative", 0))
        sentiment_up = pos > neg
        return "Aligned" if up == sentiment_up else "Divergent"
    except Exception as e:
        print(f"‚ö†Ô∏è compare_sentiment_vs_price() failed: {e}")
        return "Unknown"

def generate_summary(ticker, tech, risk, sent, port, news):
    prompt = f"""
Write a concise 2-paragraph investment summary for {ticker}.
Integrate:
Technicals: {tech}
Risk: {risk}
Sentiment: {sent}
Portfolio: {port}
News: {'; '.join(news)}
End with a recommendation.
"""
    return llm(prompt, max_new_tokens=300, temperature=0.6)[0]["generated_text"]

# ============================================================
# üöÄ Run the Multi-Agent Report
# ============================================================
def run_report(tickers):
    radar_data = []

    for t in tickers:
        display(Markdown(f"---\n# üìä {t} Analysis Page\n"))
        data = fetch_data(t)
        tech = compute_technicals(data)
        risk = compute_risk(data)
        news = fetch_news(t)
        sent = classify_sentiment(news)
        routes = route_news(news)
        port = suggest_portfolio(risk["RiskScore"])
        corr = compare_sentiment_vs_price(sent, data)
        summary = generate_summary(t, tech, risk, sent, port, news)

        # --- Price + SMA Chart ---
        fig, ax1 = plt.subplots(figsize=(10, 4))
        ax1.plot(data["Close"], label="Close", color="blue", linewidth=1.5)
        ax1.plot(data["Close"].rolling(20).mean(), label="SMA20", linestyle="--", color="orange")
        ax1.plot(data["Close"].rolling(50).mean(), label="SMA50", linestyle="-.", color="green")
        ax1.set_title(f"{t} Price & Moving Averages", fontsize=14)
        ax1.set_xlabel("Date")
        ax1.set_ylabel("Price ($)")
        ax1.legend()
        ax1.grid(True)
        plt.tight_layout()
        plt.show()

        # --- RSI Chart ---
        delta = data["Close"].diff()
        gain = delta.where(delta > 0, 0).rolling(14).mean()
        loss = -delta.where(delta < 0, 0).rolling(14).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))

        plt.figure(figsize=(10, 2))
        plt.plot(rsi, label="RSI(14)", color="purple")
        plt.axhline(70, color="red", linestyle="--", linewidth=1)
        plt.axhline(30, color="green", linestyle="--", linewidth=1)
        plt.title(f"{t} RSI Indicator", fontsize=12)
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        plt.show()

        radar_data.append([t, risk["Volatility"], risk["Drawdown"], tech["RSI"]])

        display(Markdown(f"**Summary:** {summary}"))
        display(Markdown(f"**Sentiment vs Price:** {corr}"))
        display(Markdown(f"**Suggested Allocation:** {port}"))

    display(Markdown("---\n# üß≠ Portfolio Summary Dashboard\n"))

    radar_df = pd.DataFrame(radar_data, columns=["Ticker", "Volatility", "Drawdown", "RSI"])
    radar_df.set_index("Ticker", inplace=True)
    display(Markdown("### ‚úÖ Composite Risk‚ÄìTechnical Overview"))
    display(radar_df)

    return radar_df

# ==========================================
# üöÄ Run the Final Multi-Ticker Report
# ==========================================
tickers = ["AAPL","GOOG","TSLA","AMZN","NVDA","MSFT"]
combined = run_report(tickers)

# ============================================================
# üìà Combined Radar Chart ‚Äì Key Technical & Risk Metrics
# ============================================================
plt.figure(figsize=(7,7))

labels = ["Volatility","Drawdown","RSI"]
num_vars = len(labels)
angles = np.linspace(0, 2*np.pi, num_vars, endpoint=False).tolist()
angles += angles[:1]

fig, ax = plt.subplots(figsize=(7,7), subplot_kw=dict(polar=True))

for ticker, row in combined.iterrows():
    values = [row[label] for label in labels]
    values += values[:1]
    ax.plot(angles, values, marker='o', linewidth=2, label=ticker)
    ax.fill(angles, values, alpha=0.15)

ax.set_xticks(angles[:-1])
ax.set_xticklabels(labels)
ax.set_title("üìà Combined Radar Chart ‚Äì Key Technical & Risk Metrics", size=13, y=1.1)
ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.1))
plt.tight_layout()
plt.show()

# ============================================================
# üìò Appendix + References
# ============================================================
display(Markdown("## üìò Appendix ‚Äì Consolidated Summary Table"))
md_table(combined.round(3))

display(Markdown("""
# üìö References & Tools
- **Data:** Yahoo Finance (`yfinance`)
- **News:** [NewsAPI.org](https://newsapi.org)
- **Models:** DistilBERT, Phi-3 Mini (Microsoft)
- **Libraries:** pandas, numpy, matplotlib, transformers, torch, nltk
- **Platform:** Google Colab (T4 GPU, FP16)
---
"""))

!pip install "nbconvert==7.14.2" "mistune==3.0.2" "jinja2<3.1" --force-reinstall --quiet

from google.colab import files
import nbformat, json

nb_path = "/content/FinalProject_v13.ipynb"

# 1Ô∏è‚É£ Load notebook
with open(nb_path) as f:
    nb = nbformat.read(f, as_version=4)

# 2Ô∏è‚É£ Recursively clean widget states and outputs
for cell in nb.cells:
    if "outputs" in cell:
        clean_outputs = []
        for out in cell["outputs"]:
            if "data" in out:
                # Remove widget MIME types that cause KeyError: 'state'
                bad_keys = [
                    "application/vnd.jupyter.widget-view+json",
                    "application/vnd.jupyter.widget-state+json"
                ]
                for bk in bad_keys:
                    if bk in out["data"]:
                        del out["data"][bk]
            clean_outputs.append(out)
        cell["outputs"] = clean_outputs

    # Also remove any top-level widget metadata safely
    if "metadata" in cell and "widgets" in cell["metadata"]:
        del cell["metadata"]["widgets"]

# 3Ô∏è‚É£ Save cleaned notebook
clean_path = "/content/FinalProject_v13_clean.ipynb"
with open(clean_path, "w") as f:
    nbformat.write(nb, f)

# 4Ô∏è‚É£ Convert to HTML using simplest exporter
!jupyter nbconvert --to html --template classic FinalProject_v13_clean.ipynb

# 5Ô∏è‚É£ Download
files.download("FinalProject_v13_clean.html")

!jupyter nbconvert --to html --output "FinalProject_v13_clean.html" /content/FinalProject_v13_clean.ipynb